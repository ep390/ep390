---
title: "Assignment 7: Music Generation Research"
excerpt: "Research a music generation model or product and present your findings to the class."
---

## Overview

In this assignment, you will research an existing generative music system. You will:

- Pick one of the musical systems below to research
- Spend time working with the music system to understand its strengths and weaknesses
- Create documentation of what you learned in a new web page
- Present the music creation process to the class, and play us some music you
  created with this process

## 1 Prepare

1. Ensure the dev server runs locally (see [Getting Started](/modules/getting-started)).
1. Create a new branch for this homework, e.g., `yourname-hwX`.

## 2 Choose a model or service

Choose one of the systems below. It can be a commercial product or an open-source audio
model. If you have another system in mind, seek approval from the instructor.
**It must be a system that generates audio waveforms**, not symbolic music.

### Commercial/closed-source apps

- [Google Lyria Realtime](https://deepmind.google/models/lyria/realtime/)
- [Suno](https://suno.com/) (See also: Suno Studio)
- [~~Udio~~](https://www.udio.com/)
- [Mozart AI](https://getmozart.ai/) (AI DAW)
- [Moises](https://moises.ai/) (AI DAW Desktop & Mobile Apps)

### Open models

- [Stable Audio Open (arXiv)](https://arxiv.org/abs/2407.14358) ([Huggingface](https://huggingface.co/stabilityai/stable-audio-open-1.0))
- [YuE (GitHub)](https://github.com/multimodal-art-projection/YuE) ([Examples](https://map-yue.github.io/))
- [DiffRhythm](https://github.com/ASLP-lab/DiffRhythm) ([Huggingface](https://huggingface.co/spaces/ASLP-lab/DiffRhythm))
- [SongBloom (Examples)](https://cypress-yang.github.io/SongBloom_demo/) (Must run independently)
- [LeVo: High-Quality Song Generation with Multi-Preference Alignment (GitHub)](https://github.com/tencent-ailab/SongGeneration) ([Huggingface Space](https://huggingface.co/spaces/waytan22/SongGeneration-LeVo))

## 3 Study the model

Spend time working with the model to understand how it works. What is it good at,
and where does it struggle? Document your findings on your page. Use an `<audio>`
element, and place audio files under `website/public/students/your-name/` (as in
the symbolic music assignment).

ðŸš¨ **Important:** Use a data-compressed audio file format like `.mp3`. Do not
upload uncompressed audio formats like `.wav`.

## 4 Create your page

Create a page at `website/app/students/your-name/hw7/page.jsx` that includes:

- A short description of the system you chose and why
- At least 2â€“3 audio examples generated by the system with brief notes
- A short reflection on strengths/weaknesses and creative potential

## 5 Submit your assignment

1. Commit your new page and any supporting assets (e.g., screenshots) to your branch.
1. Push to GitHub and open a Pull Request into `main`.
1. Do not merge your own PR.

## 6 Present your findings

Come to class ready to present your findings. You must show the interface you
used (Hugging Face Space, commercial web app, or code demonstration) and briefly
demonstrate how it works: your inputs, key settings/parameters, how you generate
audio, and play back the result.

## Grading Rubric

- **20** Page renders correctly
- **10** PR changes only files in the correct directory
- **10** Correct file/directory structure (e.g., `.../students/your-name/hw7/page.jsx`)
- **10** Single dedicated branch
- **15** Clear documentation of the system with 2â€“3 audio examples
- **10** Insightful analysis of strengths, weaknesses, and creative potential
- **10** Original music excerpt included and playable
- **10** Sources/links to the system and any references
- **10** In-class interface demo: showed the interface (even if on Hugging Face) and demonstrated how it works
- **15** Correct use of the static folder to save your audio, including a data-compressed format such as `.mp3` (do not use a `.wav` file)
